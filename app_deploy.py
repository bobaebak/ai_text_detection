import streamlit as st
import os
import sys
import plotly.express as px
import nltk
from nltk.corpus import stopwords
import string

nltk.download('punkt')


CURR_DIR = os.path.dirname(os.path.abspath(__file__))
PARENT_DIR  = os.path.dirname(CURR_DIR)
# print(CURR_DIR)
# print(PARENT_DIR)

# sys.path.append("".join(CURR_DIR))

import openai_detector 
import openai_finetune_detector 
import radar_detector
import gptzero_detector
import detectgpt_detector
import radar_finetune_detector
import matplotlib.pyplot as plt


def preprocess_text(text):
    tokens = nltk.word_tokenize(text.lower())
    stop_words = set(stopwords.words('english'))
    tokens = [token for token in tokens if token not in stop_words and token not in string.punctuation]
    return tokens

def plot_bar(**kwargs):
    if 'x' not in kwargs:
        return None 
    if 'y' not in kwargs:
        return None 
    
    fig = px.bar(**kwargs)
    st.plotly_chart(fig, use_container_width=True)

def final_prediction_weighted(classifiers_predictions, weights=[0.53, 0.94, 0.51, 0.74, 0.50, 0.90]):
    weighted_sum = {sentiment: 0 for sentiment in set(classifiers_predictions)}
    for prediction, weight in zip(classifiers_predictions, weights):
        weighted_sum[prediction] += weight
    final_sentiment = max(weighted_sum, key=weighted_sum.get)
    return final_sentiment

def main():
    text_area = st.text_area("Enter the text you want to analyze", height=200)
    # text = st.text_area("Enter the text you want to analyze", height=200)


    if text_area is not None:
        if st.button("Check"):
            input = text_area.strip()
            
            col1, col2, col3 = st.columns([1,1,1])
            with col1:
                ######################## basic statistics
                st.info("Basic Analysis")

                tokens = preprocess_text(input)
                word_freq = nltk.FreqDist(tokens)
                most_common_words = word_freq.most_common(10)

                words, counts = zip(*most_common_words)
                args = {
                    "x": words,
                    "y": counts, 
                    "labels": {"x": "Words", "y": "Frequency"},
                    "title": "Most Common Words",
                    # "color": "continent",
                    "color_discrete_sequence": px.colors.qualitative.Pastel,
                }
                plot_bar(**args)

                ######################## run openai detector                
                st.info("OpenAI RoBERTa Large")
                result_1 = models.openai_detector.detect(input)
                
                # st.write("AI-generated likelihood: ", round(result_1['Fake'], ndigits=3))
                # st.write("Human-generated likelihood: ", round(result_1['Real'], ndigits=3))
                
                # Create a slider bar
                st.slider(":robot_face:", min_value=0.0, max_value=1.0, value=float(result_1['Fake']), step=0.01, disabled=True)
                st.slider(":grinning:", min_value=0.0, max_value=1.0, value=float(result_1['Real']), step=0.01, disabled=True)

                ######################## run fine-tuned
                st.info("OpenAI RoBERTa Fine-tuned")
                result_2 = models.openai_finetune_detector.detect(input, None, None, "20240523_v1_epoch4.pth")
                st.slider(":robot_face:", min_value=0.0, max_value=1.0, value=float(result_2['Fake']), step=0.01, disabled=True)
                st.slider(":grinning:", min_value=0.0, max_value=1.0, value=float(result_2['Real']), step=0.01, disabled=True)



            with col2:
                ######################## run gptzero
                st.info("GPTZero")
                result_4 = models.gptzero_detector.detect(input)
                st.slider(f"Threshold: {result_4['perplexity_per_line_avg']}", 0.0, 100.0, tuple(float(x) for x in result_4['threshold']), disabled=True)
                st.markdown(f"- *Threshold < {result_4['threshold'][0]}:* The Text is generated by AI")
                st.markdown(f"- *{result_4['threshold'][0]} <= Threshold < {result_4['threshold'][1]}:* The Text is most probably contain parts which are generated by AI")
                st.markdown(f"- *{result_4['threshold'][1]} >= Threshold:* The Text is written by Human")
                
                # Plot the bar chart using Plotly for perplexity per sentence
                perplexity_per_line_ = result_4['perplexity_per_line']
                args = {
                    "x": [i for i in range(len(perplexity_per_line_))],
                    "y": perplexity_per_line_, 
                    "labels": {"x": "Sentence", "y": "Perplexity"},
                    "title": "Perplexity per sentence",
                    "color_discrete_sequence": px.colors.qualitative.Set3,

                }
                plot_bar(**args)
                st.success(f"""{result_4['msg']} \n
                           Perplexity: {result_4['perplexity']}, Burstiness: {result_4['burstiness']}""")

                ######################## run DetectGPT
                st.info("DetectGPT")
                result_5 = models.detectgpt_detector.detect(input)
                st.slider(f"Threshold: {result_5['mean_score']}", 0.0, 1.0, float(result_5['threshold']), disabled=True)
                st.markdown(f"- *Threshold >= {result_5['threshold']}:* The Text is generated by AI")
                st.markdown(f"- *Threshold < {result_5['threshold']}:* The Text is most likely written by Human")
                st.success(f"""{result_5['msg']}""")

            with col3:
                ######################## run radar model
                st.info("Radar Vicuna")
                result_3 = models.radar_detector.detect(input)
                st.slider(":robot_face:", min_value=0.0, max_value=1.0, value=float(result_3['Fake']), step=0.01, disabled=True)
                st.slider(":grinning:", min_value=0.0, max_value=1.0, value=float(result_3['Real']), step=0.01, disabled=True)

                ######################## run radar model
                st.info("Radar Vicuna Fine-tuned")
                result_6 = models.radar_finetune_detector.detect(input)
                st.slider(":robot_face:", min_value=0.0, max_value=1.0, value=float(result_6['Fake']), step=0.01, disabled=True)
                st.slider(":grinning:", min_value=0.0, max_value=1.0, value=float(result_6['Real']), step=0.01, disabled=True)

                ######################## run ensemble model
                st.info("Ensemble Models")
                pred_1 = "Real" if float(result_1['Real']) > float(result_1['Fake']) else "Fake"
                pred_2 = "Real" if float(result_2['Real']) > float(result_2['Fake']) else "Fake"
                pred_3 = "Real" if float(result_3['Real']) > float(result_3['Fake']) else "Fake"
                pred_4 = "Real" if result_4['label'] == 1 else "Fake"
                pred_5 = "Real" if result_5['label'] == 1 else "Fake"
                pred_6 = "Real" if float(result_6['Real']) > float(result_6['Fake']) else "Fake"
                classifiers_predictions = [pred_1, pred_2, pred_3, pred_4, pred_5, pred_6]  
                # classifiers_predictions = [pred_1, pred_2, pred_3, pred_4, pred_6]  
                result_7 = final_prediction_weighted(classifiers_predictions)
                label = "Human" if result_7 == "Real" else "AI"
                st.success(f"""The Text is written by {label}""")



            
            

if __name__ == "__main__":

    st.set_page_config(layout="wide")
    st.title("AI Text Analysis")

    main()