{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizer_config.json: 100%|█████████████████| 25.0/25.0 [00:00<00:00, 41.5kB/s]\n",
      "config.json: 100%|█████████████████████████████| 519/519 [00:00<00:00, 1.87MB/s]\n",
      "vocab.json: 100%|█████████████████████████████| 899k/899k [00:00<00:00, 935kB/s]\n",
      "merges.txt: 100%|█████████████████████████████| 456k/456k [00:00<00:00, 647kB/s]\n",
      "tokenizer.json: 100%|██████████████████████| 1.36M/1.36M [00:01<00:00, 1.12MB/s]\n",
      "model.safetensors: 100%|███████████████████| 1.43G/1.43G [04:08<00:00, 5.74MB/s]\n",
      "Some weights of the model checkpoint at openai-community/roberta-large-openai-detector were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/Users/bobaebak/anaconda3/envs/ai_detector/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2674: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "{'Fake': 0.5336293, 'Real': 0.46637073}\n"
     ]
    }
   ],
   "source": [
    "!python ../models/openai_detector.py --text \"My name is bobae bak\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at openai-community/roberta-base-openai-detector were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/Users/bobaebak/anaconda3/envs/ai_detector/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2674: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "{'Fake': 0.6938189, 'Real': 0.30618104}\n"
     ]
    }
   ],
   "source": [
    "!python ../models/openai_detector.py --text \"I believe that I will follow my interest. I'm not saying that studying a subject for job opportunities is wrong, it's just that I'm not that kind of person. Me myself want to be a scientist in the future, and following my own interests are rather important, because doing research can be tedious or frustrating in many situations, and my interests may be the only thing to keep me going on and on. If you are only driven by profit, it's likely that you will abandon your current subject once it seems not so profitable, and that's clearly not good for the development of science.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI Fine-tuned Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/bobaebak/anaconda3/envs/ai_detector/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2674: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "{'Fake': 0.6367217, 'Real': 0.3632783}\n"
     ]
    }
   ],
   "source": [
    "!python ../models/openai_finetune_detector.py --text \"My name is bobae bak\" --model_name \"fine_tune_epoch1.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/bobaebak/anaconda3/envs/ai_detector/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2674: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "{'Fake': 0.036566377, 'Real': 0.9634336}\n"
     ]
    }
   ],
   "source": [
    "!python ../models/openai_finetune_detector.py --text \"The place I'm most eager to visit is outer space, where many of the physical laws that govern the earth no longer apply. It's fascinating to see everything suspended in mid-air. And, of course, the phrase \\\"in mid-air\\\" needs a tweak, given that there's no air to speak of. It's exhilarating to move about in a completely novel way. And it's breathtaking to gaze upon our home planet from a radically new perspective. The big blue crystal sphere, as captured in the stunning images taken by astronauts, is simply awe-inspiring. I'm desperate to lay eyes on this magnificent blue orb in person.\" --model_name \"fine_tune_epoch1.pth\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Radar Vicuna Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Fake': 0.9963961243629456, 'Real': 0.0036038756370544434}\n"
     ]
    }
   ],
   "source": [
    "!python ../models/radar_detector.py --text \"My name is bobae bak\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPTZero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lines': [\"The system's availability was compromised due to a wiped master boot record and overwritten files by a wiper. \", 'To prevent such attacks, updating the OS to a newer version with enhanced security features and using reliable, up-to-date antivirus software are essential measures to protect against malware.'], 'burstiness': 135, 'perplexity': 37, 'perplexity_per_line_avg': 78.0, 'perplexity_per_line': [135, 21], 'msg': 'The Text is most probably contain parts which are generated by AI. (require more text for better Judgement)', 'label': 0, 'threshold': (60, 80)}\n"
     ]
    }
   ],
   "source": [
    "!python ../models/gptzero_detector.py --text \"The system's availability was compromised due to a wiped master boot record and overwritten files by a wiper. To prevent such attacks, updating the OS to a newer version with enhanced security features and using reliable, up-to-date antivirus software are essential measures to protect against malware.\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_detector",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
