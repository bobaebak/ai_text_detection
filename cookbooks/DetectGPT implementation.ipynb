{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import DetectGPTRunner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probability for Human: 92.83%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'prob': '92.83%', 'label': 1},\n",
       " 'This text is most likely written by an Human')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DetectGPTRunner('mps', 'gpt2-medium')\n",
    "sentence = \"Hello world Hello world Hello world Hello world Hello world Hello world Hello world Hello world Hello world Hello world Hello world Hello world Hello world Hello world Hello world Hello world\" \n",
    "\n",
    "model(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probability for Human: 60.04%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'prob': '60.04%', 'label': 1},\n",
       " 'This text is most likely written by an Human')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DetectGPTRunner('mps', 'gpt2-medium')\n",
    "sentence = \"\"\"\n",
    "The probability output from a T5 model, or any neural language model like it, typically represents the likelihood of a particular sequence of tokens given the context provided to the model. This probability is calculated using the model's learned parameters and is often normalized across all possible sequences to sum up to 1.\n",
    "\n",
    "Using log-probabilities in inference has several advantages:\n",
    "\n",
    "Numerical Stability: When dealing with probabilities, especially when multiplying many small probabilities together (which can lead to underflow issues), taking logarithms helps maintain numerical stability.\n",
    "Mathematical Convenience: Logarithms simplify mathematical operations, especially multiplication and division, into addition and subtraction. This simplifies calculations in the model and makes it more computationally efficient.\n",
    "Prediction Confidence: Log-probabilities provide a clearer representation of the model's confidence in its predictions. A higher log-probability indicates a higher confidence in the predicted sequence, whereas a lower log-probability suggests less confidence.\n",
    "Training Optimization: In the context of training neural networks, using log-probabilities is common because it allows the loss function to be formulated as the negative log-likelihood. This is a standard formulation in maximum likelihood estimation, which is widely used in training neural networks.\n",
    "\"\"\"\n",
    "model(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probability for Human: 86.98%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'prob': '86.98%', 'label': 1},\n",
       " 'This text is most likely written by an Human')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"\"\"\n",
    "The explosive growth in AI is one of the most conspicuous signs of technological development. Due to the exponential usage of AI tools, many students employ them as co-pilots.\n",
    "\n",
    "The problem is that it was deemed acceptable to use them only for reference purposes, but reality wasn’t like that.\n",
    "\n",
    "Many cases of abuse were detected, where students simply copied machine-generated texts and pasted them onto their assessments and essays.\n",
    "\n",
    "Some social media platforms exhibit tricky methods to bypass AI detection by regenerating or paraphrasing the machine-written text.\n",
    "\n",
    "Given this social phenomenon of exploiting AI, many stakeholders in high-level educational organizations must be aware of this.\n",
    "\n",
    "This project aims to help raise awareness of educational integrity for the future education landscape.\n",
    "\"\"\"\n",
    "model(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probability for Human: 90.55%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'prob': '90.55%', 'label': 1},\n",
       " 'This text is most likely written by an Human')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"\"\"\n",
    "We find that large language models (LLMs) are more likely to modify human- written text than AI-generated text when tasked with rewriting. This tendency arises because LLMs often perceive AI-generated text as high-quality, leading to fewer modifications. We introduce a method to detect AI-generated content by prompting LLMs to rewrite text and calculating the editing distance of the out- put. We dubbed our geneRative AI Detection viA Rewriting method Raidar. Raidar significantly improves the F1 detection scores of existing AI content de- tection models – both academic and commercial – across various domains, in- cluding News, creative writing, student essays, code, Yelp reviews, and arXiv papers, with gains of up to 29 points. Operating solely on word symbols without high-dimensional features, our method is compatible with black box LLMs, and is inherently robust on new content. Our results illustrate the unique imprint of machine-generated text through the lens of the machines themselves.\"\"\"\n",
    "model(sentence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "detect_gpt_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
